{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from convert_eprime import convert as ep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "source_dir = os.path.join('..','sourcedata')\n",
    "derivs_dir = os.path.join('..','derivatives')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define a function to clean the N-back data\n",
    "\n",
    "Stack the blocks vertically instead of horizontally, label the trial rows properly, and tag each trial as a HIT, MISS, FA, CR. We are also ouputting a new CSV data file in the sourcedata folder, all cleaned-up."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nstack_score_label(fpath,outpath):\n",
    "    df = pd.read_excel(fpath)\n",
    "    \n",
    "    # Hierarchicalize the column index\n",
    "    df.columns=pd.MultiIndex.from_tuples([\n",
    "        (df.columns[0].split('.')[0],df.columns[0].split('.')[1]),\n",
    "        (df.columns[1].split('.')[0],df.columns[1].split('.')[1]),\n",
    "        (df.columns[2].split('.')[0],df.columns[2].split('.')[1]),\n",
    "        (df.columns[3].split('.')[0],df.columns[3].split('.')[1]),\n",
    "        (df.columns[4].split('.')[0],df.columns[4].split('.')[1]),\n",
    "        (df.columns[5].split('.')[0],df.columns[5].split('.')[1]),\n",
    "    ])\n",
    "    \n",
    "    # Stack blocks, Reset trial row index, and Rename columns to be descriptive\n",
    "    df = df.stack(0).reset_index().rename(\n",
    "        columns={'level_0':'trial','level_1':'block'}\n",
    "    ).sort_values(['block','trial'])\n",
    "    df['sub'] = os.path.basename(fpath).split('_')[0].split('-')[1]\n",
    "    df['block'] = df['block'].str[1]\n",
    "    df['trial'] = df['trial'] + 1\n",
    "    df = df.set_index(['sub','block','trial'])\n",
    "    \n",
    "    # Determine Hits, CRs, FAs\n",
    "    cr_mask = (df['Rsp'] == 0) & (df['CRsp'] == 0)\n",
    "    ms_mask = (df['Rsp'] == 0) & (df['CRsp'] == 1)\n",
    "    fa_mask = (df['Rsp'] == 1) & (df['CRsp'] == 0)\n",
    "    ht_mask = (df['Rsp'] == 1) & (df['CRsp'] == 1)\n",
    "    df['CR']   = cr_mask.astype(int)\n",
    "    df['MISS'] = ms_mask.astype(int)\n",
    "    df['FA']   = fa_mask.astype(int)\n",
    "    df['HIT']  = ht_mask.astype(int)\n",
    "    \n",
    "    # Convert RT 0 to RT NaN\n",
    "    df['RT'] = df['RT'].replace(0,np.NaN)\n",
    "    \n",
    "    # Output to new CSV datafile\n",
    "    df.to_csv(outpath)\n",
    "    print('Output file successfully created- ',outpath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Read all the subject data\n",
    "\n",
    "Reading only data for the full sample (100-series YA & 200-series OA). Executing N-back data cleaning & EPrime text-to-csv conversion. Setting up for subject-level analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sub-101_task-nback_beh.xlsx\n"
     ]
    }
   ],
   "source": [
    "ep_frames=[]\n",
    "ptb_frames=[]\n",
    "\n",
    "for s in os.listdir(source_dir):\n",
    "    if s.startswith('sub-1') or s.startswith('sub-2'):\n",
    "        sub_dir = os.path.join(source_dir,s)\n",
    "        for f in os.listdir(sub_dir):\n",
    "            o = f.split('.')[0]+'.csv'\n",
    "            fpath = os.path.join(sub_dir,f)\n",
    "            outpath = os.path.join(sub_dir,o)\n",
    "            if f.split('_')[-1] == 'beh.txt':\n",
    "                print(f)\n",
    "                ep.text_to_csv(fpath,outpath)\n",
    "                ep_frames.append(pd.read_csv(outpath))\n",
    "            if f.split('_')[-1] == 'beh.xlsx':\n",
    "                print(f)\n",
    "                nstack_score_label(fpath,outpath)\n",
    "                ptb_frames.append(pd.read_csv(outpath))\n",
    "                ptb_frames[-1]['sub'] = f.split('_')[0].split('-')[1]\n",
    "print(\"Done!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Output N-back trial-level data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.concat(ptb_frames).to_csv(os.path.join(derivs_dir,'nback_trial_data.csv'),index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Group, expand, trim N-back data\n",
    "Group by subjects, get the sum of all columns, the count of the trial column, and the mean of the RT column.\n",
    "\n",
    "Establish Hit % `number of Hits / number of targets` and FA % `number of FAs / number of foils`. \n",
    "\n",
    "Corrected Recognition `HIT% - FA%`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "grouped = pd.concat(ptb_frames).groupby('sub')\n",
    "nback_df = grouped.sum()\n",
    "nback_df['trial'] = grouped.count()['trial']\n",
    "nback_df['RT'] = grouped.mean()['RT']\n",
    "nback_df['HIT%'] = nback_df['HIT'] / nback_df['CRsp']\n",
    "nback_df['FA%'] = nback_df['FA'] / (nback_df['trial'] - nback_df['CRsp'])\n",
    "nback_df['CoR'] = nback_df['HIT%'] - nback_df['FA%']\n",
    "nback_df = nback_df[['RT','HIT%','FA%','CoR']]\n",
    "nback_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Output N-back subject-level data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nback_df.to_csv(os.path.join(derivs_dir,'nback_subject_data.csv'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ProcSpd data\n",
    "Cleanup: Rehomogenize subject column, concatenate all frames, drop unneeded columns and rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for df in ep_frames:\n",
    "    df['Subject'] = df['Subject'][22]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "procspd_df = pd.concat(ep_frames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drop = ['DataFile.Basename','RandomSeed','Group','Display.RefreshRate','Clock.Information',\n",
    "        'StudioVersion','RuntimeVersion','RuntimeVersionExpected','RuntimeCapabilities',\n",
    "        'Experiment','SessionDate','SessionTime','SessionStartDateTimeUtc','Session',\n",
    "        'TestingList','JitterList','TestingList.Cycle','TestingList.Sample',\n",
    "        'BlockList','BlockList.Cycle','BlockList.Sample','Running',\n",
    "        'TargetStimulus.OnsetTime','TargetStimulus.DurationError','TargetStimulus.RTTime',\n",
    "        'TargetStimulus.RESP','TargetStimulus.CRESP','TargetStimulus.OnsetDelay',\n",
    "        'Buffer.OnsetTime','Buffer.OnsetDelay','Buffer.DurationError','Buffer.RTTime',\n",
    "        'Buffer.RESP','Buffer.CRESP'\n",
    "       ]\n",
    "procspd_df = procspd_df[procspd_df['Procedure']=='TrialProc'].drop(columns=drop)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Combine response windows for final RT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_rt(row):\n",
    "    initial = row['TargetStimulus.RT']\n",
    "    buffert = row['Buffer.RT']\n",
    "    initial_duration = row['TargetStimulus.OnsetToOnsetTime']\n",
    "    if initial == 0 and buffert > 0:\n",
    "        rt = buffert + initial_duration\n",
    "    elif initial > 0: rt = initial\n",
    "    else: rt = np.nan\n",
    "    return(rt)\n",
    "\n",
    "procspd_df['RT'] = procspd_df.apply(calculate_rt,axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Output Procspd trial-level data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "procspd_df.to_csv(os.path.join(derivs_dir,'procspd_trial_data.csv'),index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Group and output ProcSpd subject-level data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped = procspd_df.groupby('Subject')\n",
    "grouped.mean()[['RT']].to_csv(os.path.join(derivs_dir,'procspd_subject_data.csv'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
