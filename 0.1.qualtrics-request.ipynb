{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os,io,requests,json,zipfile,pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setting user & survey parameters\n",
    "Assumes user has api token generated and stored in text file at 'U:\\keys\\qualtrics-api-token.txt'\n",
    "\n",
    "List as many or as few qualtrics survey IDs as needed in surveyIdList\n",
    "\n",
    "Currently requires re-executing the script for each survey, as the zipfile extract fails out once per survey. I do not understand the zipfile functionality enough to troubleshoot at the moment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "apiToken = open(os.path.join('u:/','keys','qualtrics-api-token.txt'),'r').read()\n",
    "surveyIdList = [\"SV_bsl9vF012E6Thbv\",\"SV_bBNxUVhoGFcyKot\",\"SV_2gAX1ty1UjOeKBT\",\"SV_d4o0ZLBDB8GxpwV\"]\n",
    "fileFormat = \"csv\"\n",
    "dataCenter = 'ca1'\n",
    "output_dir = os.path.join('..','sourcedata','qualtrics')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setting static parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "requestCheckProgress = 0\n",
    "progressStatus = \"in progress\"\n",
    "baseUrl = \"https://{0}.qualtrics.com/API/v3/responseexports/\".format(dataCenter)\n",
    "headers = {\n",
    "    \"content-type\": \"application/json\",\n",
    "    \"x-api-token\": apiToken,\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Executing Request\n",
    "If executing in Jupyter, this is the cell that will throw an error for each survey.\n",
    "\n",
    "Simply re-execute until it stops throwing errors..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"result\":{\"id\":\"ES_62lt922fk8dhvvj99evklusm2v\"},\"meta\":{\"httpStatus\":\"200 - OK\",\"requestId\":\"eb414ec5-a990-484d-b634-f4854ca59b88\"}}\n",
      "SV_bsl9vF012E6Thbv done!\n",
      "{\"result\":{\"id\":\"ES_d2kjqtbn20mmveokg0mvt2q067\"},\"meta\":{\"httpStatus\":\"200 - OK\",\"requestId\":\"eae2b7a5-b615-4e64-95ae-8caab568fdf8\"}}\n",
      "SV_bBNxUVhoGFcyKot done!\n",
      "{\"result\":{\"id\":\"ES_djdt6cf1fq6ijrfdlc0sadfh7u\"},\"meta\":{\"httpStatus\":\"200 - OK\",\"requestId\":\"49f624f6-5587-496c-8d15-ae876db44804\"}}\n",
      "SV_2gAX1ty1UjOeKBT done!\n",
      "{\"result\":{\"id\":\"ES_uee69jscae12cqohmtgdd0t4jr\"},\"meta\":{\"httpStatus\":\"200 - OK\",\"requestId\":\"84061e51-95e1-4aa3-ab13-83ca8f59738b\"}}\n",
      "SV_d4o0ZLBDB8GxpwV done!\n",
      "All done!\n"
     ]
    }
   ],
   "source": [
    "for surveyId in surveyIdList:\n",
    "    # Step 1: Creating Data Export\n",
    "    downloadRequestUrl = baseUrl\n",
    "    downloadRequestPayload = '{\"format\":\"' + fileFormat + '\",\"surveyId\":\"' + surveyId + '\"}'\n",
    "    downloadRequestResponse = requests.request(\"POST\", downloadRequestUrl, data=downloadRequestPayload, headers=headers)\n",
    "    progressId = downloadRequestResponse.json()[\"result\"][\"id\"]\n",
    "    print(downloadRequestResponse.text)\n",
    "    \n",
    "    # Step 2: Checking on Data Export Progress and waiting until export is ready\n",
    "    while requestCheckProgress < 100 and progressStatus is not \"complete\":\n",
    "        requestCheckUrl = baseUrl + progressId\n",
    "        requestCheckResponse = requests.request(\"GET\", requestCheckUrl, headers=headers)\n",
    "        requestCheckProgress = requestCheckResponse.json()[\"result\"][\"percentComplete\"]\n",
    "        print(\"Download is \" + str(requestCheckProgress) + \"% complete\")\n",
    "    \n",
    "    # Step 3: Downloading file\n",
    "    requestDownloadUrl = baseUrl + progressId + '/file'\n",
    "    requestDownload = requests.request(\"GET\", requestDownloadUrl, headers=headers, stream=True)\n",
    "    \n",
    "    # Step 4: Unzipping the file\n",
    "    zipfile.ZipFile(io.BytesIO(requestDownload.content)).extractall(output_dir)\n",
    "    print(surveyId,'done!')\n",
    "print('All done!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read outputs, clean and re-write"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_drop=[\n",
    "    'StartDate','EndDate','Status','IPAddress','Finished',\n",
    "    'RecipientLastName','RecipientFirstName','RecipientEmail',\n",
    "    'LocationLatitude','LocationLongitude','LocationAccuracy',\n",
    "    'ResponseID','ResponseSet','ExternalDataReference',\n",
    "    'Score-weightedAvg','Score-weightedStdDev'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "for f in os.listdir(output_dir):\n",
    "    fpath = os.path.join(output_dir,f)\n",
    "    if os.path.isfile(fpath):\n",
    "        df = pd.read_csv(fpath)\n",
    "        df = df[df['Finished'] == '1']\n",
    "        df = df[[\n",
    "            c for c in df.columns\n",
    "            if not c.startswith('DO-')\n",
    "            and not c.startswith('RO-')\n",
    "            and not c in columns_to_drop\n",
    "        ]]\n",
    "        df.to_csv(fpath,index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
